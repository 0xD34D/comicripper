#!/usr/bin/env python3
import argparse
import concurrent.futures
from io import BytesIO
import sys
from lxml import html
import os
from PIL import Image
import requests
from zipfile import ZipFile

AGENT = 'Mozilla/5.0 (X11; CrOS x86_64 14324.56.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4692.70 Safari/537.36'
HEADERS = {'User-Agent': AGENT}
VERBOSE = False
MESSAGE = """
    _________                _____
    __  ____/____________ ______(_)______
    _  /    _  __ \_  __ `__ \_  /_  ___/
    / /___  / /_/ /  / / / / /  / / /__
    \____/  \____//_/ /_/ /_//_/  \___/

    _____________
    ___  __ \__(_)____________________________
    __  /_/ /_  /___  __ \__  __ \  _ \_  ___/
    _  _, _/_  / __  /_/ /_  /_/ /  __/  /
    /_/ |_| /_/  _  .___/_  .___/\___//_/
                 /_/     /_/
"""


class CrArgumentParser(argparse.ArgumentParser):

    def print_help(self, file=None):
        if file is None:
            file = sys.stdout
        file.write(MESSAGE+"\n")
        super().print_help(file=file)

    def print_usage(self, file=None):
        if file is None:
            file = sys.stdout
        file.write(MESSAGE+"\n")
        super().print_usage(file=file)
        

class ComicBook:
    headers = HEADERS

    def __init__(self, url, title, pages):
        self.title = title
        self.url = url
        self.pages = pages
        self.numPages = len(pages)

    @classmethod
    def fromUrl(cls, url):
        page = requests.get(url, headers=cls.headers)
        tree = html.fromstring(page.content)
        title = tree.find('.//title').text
        # strip off the garbage at the end of the comic book title
        title = " ".join(title.split()).split(' - Page ')[0].replace(':', ' -')
        pages = tree.xpath('.//div[@id="all"]')[0].xpath('.//img')

        return cls(url, title, pages)


def fetch_page(url: str) -> bytes:
    r = requests.get(url, headers=HEADERS)
    img = Image.open(BytesIO(r.content)).convert('RGB')
    with BytesIO() as output:
        img.save(output, quality=50, format='JPEG')
        return output.getvalue()


def fetch_comic(comicBook: ComicBook, overwrite: bool):
    zipFile = '%s.cbz' % comicBook.title
    if os.path.exists(zipFile) and not overwrite:
        print('%s exists, skipping...' % zipFile)
        return
    
    # no pages means no comic book for you!
    if comicBook.numPages <= 0:
        print('Could not find any pages for %s' % comicBook.title)
        exit()

    # download and zip up the pages
    print('Processing %d pages for %s' % (comicBook.numPages, comicBook.title))

    with ZipFile(zipFile, 'w') as cbz:
        pages = []
        for i in range(0, comicBook.numPages):
            pageName = comicBook.pages[i].xpath('@alt')[0]
            pageUrl = comicBook.pages[i].xpath('@data-src')[0].strip()
            page = fetch_page(pageUrl)
            pages.append((page, pageName, i))
            if VERBOSE: print('Downloading %s...' % pageName)
        for page in pages:
            if VERBOSE: print('Adding %s to %s' % (page[1], zipFile))
            cbz.writestr('%04d.jpg' % page[2], page[0])


if __name__ == '__main__':
    parser = CrArgumentParser(description='Download series of comic books from readcomics.ru.')
    parser.add_argument('url', type=str, nargs=1, help='readcomics.ru URL to parse')
    parser.add_argument('-o', '--overwrite', action='store_true', default=False, help='overwrite existing files')
    parser.add_argument('-s', '--single', action='store_true', default=False, help='process a single comic')
    parser.add_argument('-v', '--verbose', action='store_true', default=False, help='verbose output')
    args = parser.parse_args()
    VERBOSE = args.verbose

    comicsUrl = args.url[0]
    if args.single:
        fetch_comic(ComicBook.fromUrl(comicsUrl), args.overwrite)
    else:
        page = requests.get(comicsUrl)
        tree = html.fromstring(page.content)
        comicUrls = tree.xpath('.//ul[@class="chapters"]/li/h5/a/@href')
        with concurrent.futures.ThreadPoolExecutor() as executor:
            future_to_url = {
                executor.submit(
                    fetch_comic,
                    ComicBook.fromUrl(comicUrl),
                    args.overwrite): comicUrl for comicUrl in comicUrls
            }
            for future in concurrent.futures.as_completed(future_to_url):
                comicUrl = future_to_url[future]
                print('%s finished...' % comicUrl)
