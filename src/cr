#!/usr/bin/env python3
import argparse
from ComicBook import ComicBook
import concurrent.futures
from lxml import html
import os
import requests
import sys
from zipfile import ZipFile

AGENT = 'Mozilla/5.0 (X11; CrOS x86_64 14324.56.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4692.70 Safari/537.36'
HEADERS = {'User-Agent': AGENT}
VERBOSE = False
MESSAGE = """
    _________                _____
    __  ____/____________ ______(_)______
    _  /    _  __ \_  __ `__ \_  /_  ___/
    / /___  / /_/ /  / / / / /  / / /__
    \____/  \____//_/ /_/ /_//_/  \___/

    _____________
    ___  __ \__(_)____________________________
    __  /_/ /_  /___  __ \__  __ \  _ \_  ___/
    _  _, _/_  / __  /_/ /_  /_/ /  __/  /
    /_/ |_| /_/  _  .___/_  .___/\___//_/
                 /_/     /_/
"""


class CrArgumentParser(argparse.ArgumentParser):

    def print_help(self, file=None):
        if file is None:
            file = sys.stdout
        file.write(MESSAGE + '\n')
        super().print_help(file=file)

    def print_usage(self, file=None):
        if file is None:
            file = sys.stdout
        file.write(MESSAGE + '\n')
        super().print_usage(file=file)


def ripComic(comicBook: ComicBook, overwrite: bool, path: str):
    zipFile = os.path.abspath(path) + os.path.sep + f'{comicBook.title}.cbz'
    if os.path.exists(zipFile) and not overwrite:
        print(f'{zipFile} exists, skipping')
        return

    # no pages means no comic book for you!
    if comicBook.numPages <= 0:
        print(f'Could not find any pages for {comicBook.title}')
        exit()

    # download and zip up the pages
    print(f'Processing {comicBook.numPages} pages for {comicBook.title}')

    with ZipFile(zipFile, 'w') as cbz:
        comicBook.fetchPages()
        for page in comicBook.pages:
            if VERBOSE:
                print(
                    f'Adding page [{page.number+1}/{comicBook.numPages}] to \'{os.path.basename(zipFile)}\''
                )
            cbz.writestr(f'{page.number:04}.jpg', page.image)


if __name__ == '__main__':
    parser = CrArgumentParser(
        description='Download series of comic books from readcomics.ru.')
    parser.add_argument(
        'url',
        type=str,
        nargs=1,
        help='readcomics.ru URL to parse',
    )
    parser.add_argument(
        '-o',
        '--overwrite',
        action='store_true',
        default=False,
        help='overwrite existing files',
    )
    parser.add_argument(
        '-p',
        '--path',
        type=str,
        nargs=1,
        default=None,
        help='path to output to',
    )
    parser.add_argument(
        '-s',
        '--single',
        action='store_true',
        default=False,
        help='process a single comic',
    )
    parser.add_argument(
        '-v',
        '--verbose',
        action='store_true',
        default=False,
        help='verbose output',
    )
    args = parser.parse_args()
    VERBOSE = args.verbose

    comicsUrl = args.url[0]
    path = '' if args.path is None else args.path[0]
    if args.single:
        ripComic(ComicBook.fromUrl(comicsUrl), args.overwrite, path)
    else:
        page = requests.get(comicsUrl)
        tree = html.fromstring(page.content)
        comicUrls = tree.xpath('.//ul[@class="chapters"]/li/h5/a/@href')
        with concurrent.futures.ThreadPoolExecutor() as executor:
            future_to_url = {
                executor.submit(ripComic, ComicBook.fromUrl(comicUrl),
                                args.overwrite, path): comicUrl
                for comicUrl in comicUrls
            }
            for future in concurrent.futures.as_completed(future_to_url):
                comicUrl = future_to_url[future]
                print(f'{comicUrl} finished...')
